\chapter{Ambiente de \textit{Data Warehousing} para Métricas de Código-Fonte}
\label{chap:arquitetura}

\section{Arquitetura do Ambiente \textit{Data Warehousing} para Métricas de Código-Fonte}
Para a implementação do ambiente de \textit{Data Warehousing} para métricas de código-fonte, foi definida a arquitetura tal como se mostra Figura \ref{arquitetura}.

\begin{figure}[ht!]
\centering
\includegraphics[keepaspectratio=false,scale=0.20]{figuras/arquitetura-dwing.eps}
\caption{Arquitetura do Ambiente de \textit{Data Warehousing} para Métricas de Código-Fonte}
\label{arquitetura}
\end{figure}
\FloatBarrier

Para selecionar as ferramentas, que implementarão cada um dos componentes, estabeleceram-se critérios gerais de seleção tal como pode ser visto na Tabela \ref{seleção}.


	\begin{table}[!ht]
	\begin{center}
	\input{tabelas/selecao.ltx}
	\caption{Critérios Gerais de seleção de ferramentas}
	\label{seleção}
	\end{center}
	\end{table}	


\section{Ferramenta de Análise Estática de Código-Fonte}

Além dos critérios gerais estabelecidos para escolha da ferramenta de análise estática de código-fonte, que é a fonte externa de coleta dos dados, estabeleceram-se os critérios específicos para seleção de ferramentas de análise estática de código fonte (CAE) apresentados na Tabela \ref{specific}.


	\begin{table}[!ht]
	\begin{center}
	\input{tabelas/specific.ltx}	
	\caption{Critérios Específicos para Ferramenta de Análise Estática de Código-Fonte}
	\label{specific}
	\end{center}
	\end{table}	

Após a realização de uma busca por ferramentas de análise estática de código-fonte, foram pre-selecionados o SonarQube~\footnote{Disponível em \url{http://www.sonarqube.org/}} e Analizo~\footnote{Disponível em \url{http:/http://analizo.org/}} cujas principais características de ambas são apresentadas na Tabela \ref{dados-ferramentas-estatica}.

\begin{savenotes}
\begin{table}[!ht]
\centering
\input{tabelas/ferramentas.ltx}
\caption{Características do SonarQube e do Analizo}
\label{dados-ferramentas-estatica}
\end{table}
\FloatBarrier
\end{savenotes}

Tendo as características gerais de cada ferramenta levantadas, foram comparadas (SonarQube e Analizo) quanto aos critérios gerais e aos critérios específicos para ferramentas de análise estática, tal como se mostra na Tabela \ref{compare}.


\begin{table}[!ht]
\centering
\input{tabelas/compare.ltx}
\caption{Análise do SonarQube e do Analizo quanto aos critérios gerais e quanto aos critérios específicos de ferramentas de análise estática}
\label{compare}
\end{table}
\FloatBarrier

Em fase inicial do trabalho, fora feita a análise entre o Analizo e o SonarQube, que resultou na decisão de utilizar o SonarQube. Contudo, desde a versão 4.1, o SonarQube retirou as métricas: \textbf{LCOM4, RFC, DIT, NOC}~\footnote{CoreMetrics do SonarQube: \url{https://github.com/SonarSource/sonarqube/blob/master/sonar-plugin-api/src/main/java/org/sonar/api/measures/CoreMetrics.java}}. Dado que este fato, impacta sobre o principal objetivo do trabalho, migrou-se para a ferramenta Analizo. Esta evoluiu e ganhou a possibilidade de emitir saídas das métricas em CSV que detalham nome da classe e as respectivas métricas, atendendo assim ao critério CAE02. Adicionalmente, o Analizo permitiu ao trabalho incorporar a análise das métricas \textbf{ANPM, AMLOC, CBO, NPA}, que como foi observado na Seção \ref{sec:clean-code}, são cruciais na detecção de cenários de limpeza de código-fonte.

\section{Projeto do \textit{Data Warehouse}}

O \textit{Data Warehouse} como elemento central do ambiente de \textit{Data Warehousing} deve ser o primeiro a ser projetado \cite{Kimball2002}. Isso ocorre pois o DW deve ser dirigido ao negócio. Logo a modificação do DW impacta principalmente na carga dos dados, na etapa de extração, transformação e carga, requerendo modificações conforme o DW venha a mudar.

Seguindo a metolodogia proposta por \citeonline{Kimball2002}, apresentada na Seção \ref{sec:metodologia-dw}, identificou-se dois processos de negócio. Para o primeiro processo de negócio: coleta dos percentis da métricas de código-fonte e intervalos qualitativos conforme as configurações especificadas como especificado na Seção \ref{sec:Intervalos das Métricas}, foram identificados requisitos de negócio, como se mostra na Tabela \ref{requisitos}.

\begin{table}[!ht]
\centering
\input{tabelas/requisitos.ltx}
\caption{Requisitos de Negócio da Coleta de Percentis e Intervalos Qualitativos de Métricas de Código-Fonte}
\label{requisitos}
\end{table}
\FloatBarrier

Considerando então que cada requisito de negócio é utilizado em cada uma das métricas da Tabela \ref{tab:good-metrics}, obtém um total de 96 requisitos de negócio para o primeiro processo de negócio. Dando prosseguimento na metodologia proposta de \citeonline{Kimball2002}, identificou-se a periodicidade como releases do software, isto é, cada software pode ter tempos diferenciados de release. Em alguns casos, estas podem ser semestrais ou mensais, contudo em outros casos, é possível obter releases diárias, como resultado da integração de um determinada massa de código em um sistema de integração continua \cite{beckarticle1999}. 

Aplicando o terceiro passo e quarto passo da metodologia de \citeonline{Kimball2002}, identificou-se os fatos e as dimensões a partir da Tabela \ref{requisitos}, onde os termos em negritos foram candidatos a dimensão ou a fato. A partir da análise 


 obtendo assim a Figura \ref{dimensoes}, onde o amarelo é o fato, vermelho são as dimensões e azul os atributos de dimensões  


\begin{figure}[ht!]
\centering
\includegraphics[keepaspectratio=true,scale=0.13]{figuras/dimensoes.eps}
\caption{Dimensões e Fatos da Coleta de Percentis e Intervalos Qualitativos de Métricas de Código-Fonte}
\label{dimensoes}
\end{figure}
\FloatBarrier


O segundo processo de negócio, é a avaliação, em nível de classe, da aplicação de cenários de limpeza de código-fonte, conforme a Seção \ref{sec:clean-code}.






\todo[inline, color=yellow!50]{Atualizar a seção com as informações de hierarquia, entidades de negócio, granularidade, dimesões e fatos}


\section{Ferramentas de \textit{Data Warehousing}}

Tendo em vista que o \textit{Data Warehouse} foi projetado em um modelo dimensional, é possível construir tanto o processo de \textit{Extraction-Transformation-Load} quanto as operações de consulta OLAP. Entre as alternativas de código aberto que suportam este ambiente como um todo, está o Pentaho BI Suite Community Edition. Este apresenta soluções que cobrem 
as áreas de ETL, \textit{reporting}, OLAP e mineração de dados. Cada um dos componentes utilizados é apresentado e analisado nas seções subsequentes.
 


\subsection{Implementação da Extração, Transformação e Carga dos Dados}
\label{implementação-ETL}
O Pentaho Data Integration Community Edition ou Kettle\footnote{Disponível em \url{http://kettle.pentaho.com/}} é feito na linguagem Java e implementa o processo de ETL (Extração, Transformação e Carga de Dados). A interface do Kettle é mostrada na Figura \ref{pdi} e as principais características do Kettle e a análise quanto aos critérios gerais de seleção de ferramentas são apresentadas na Tabela \ref{kettle}.

\begin{figure}[ht!]
\centering
\includegraphics[keepaspectratio=false,scale=0.38]{figuras/data-integration.eps}
\caption{Interface do Kettle}
\label{pdi}
\end{figure}
\FloatBarrier
 

\begin{table}[!ht]
\input{tabelas/kettle.ltx}
\caption{Características do Kettle e avaliação quanto aos critérios gerais de seleção de ferramentas}
\label{kettle}
\end{table}
\FloatBarrier	

O Kettle possui dois tipos de componentes internos: \textit{Job} e \textit{Transformation}. O primeiro permite executar tarefas, em nível mais alto, de fluxo de controle, tais como, mandar um email em caso de falha, baixar um arquivo, executar transformações  e entre outras atividades. Já a \textit{Transformation} permite tratamento aos dados incluindo desde entrada de dados por diversas fontes até a persistência em uma variedade de SGBDs.


Para a implementação do ETL no Kettle, utilizou-se dos arquivos CSV resultantes da análise de métricas de código-fonte do Analizo. Embora, o Kettle tivesse componentes de interpretação dos elementos de CSV, no presente trabalho, decidiu-se por converter CSV obtido do Analizo em arquivos JSON, visto que componente de CSV do Kettle, converte-o para XML, sendo que este é mais lento e menos versátil quando comparado ao JSON, tal como se mostra no trabalho de \citeonline{fonseca2007alternativas}. Visando realizar a conversão, foi escrito um pequeno \textit{parser} na linguagem \textit{Ruby}, tal como se vê no Código-Fonte \ref{Ruby}.

\begin{center}
\begin{minipage}{0.5\textwidth}
\lstinputlisting[caption=\textit{Parser} de CSV para JSON, language=Ruby, label=Ruby]{codigos/parser.rb}
\end{minipage}
\end{center}

Todas as implementações de \textit{Transformation} e \textit{Job} que foram elaboradas no decorrer do trabalho foram descritas em detalhes no apêndice \ref{implementação}.


\subsection{Implementação das Consultas OLAP e Visualização de Dados}

Para a implementação das consultas OLAP e Visualização de dados, torna-se necessário a utilização do Pentaho BI Platform\footnote{Disponível em \url{http://community.pentaho.com/projects/bi_platform/}}, que é uma ferramenta que provê a arquitetura e a infraestrutura para soluções de \textit{Business Inteligence}, \textit{Data Mining} e a camada de visualização de dados do \textit{Data Warehouse}.


O Pentaho BI Platform, cuja interface inicial é apresentada na Figura \ref{BIplatform}, tem as principais características e a análise quanto aos critérios gerais de seleção de ferramentas são apresentadas na Tabela \ref{biserver}. 


\begin{table}[!ht]
\input{tabelas/biserver.ltx}
\caption{Características do Pentaho BI Platform e avaliação quanto aos critérios gerais de seleção de ferramentas}
\label{biserver}
\end{table}
\FloatBarrier



\begin{figure}[ht!]
\begin{center}
\includegraphics[keepaspectratio=false, scale=0.35]{figuras/bi.eps}
\caption{Interface Gráfica do Pentaho BI Platform}
\label{BIplatform}
\end{center}
\end{figure}
\FloatBarrier
 

A ferramenta Pentaho BI Platform possui arquitetura extensível por plugins diversos que realizam diversas operações, tais como, criação de relatórios, visualização dos dados em tabelas e gráficos e entre outros. Entre os plugins disponíveis, está o Saiku Analytics que oferece serviços de apoio a operações OLAP e à visualização de dados. As características gerais do Saiku Analytics, bem como a avaliação quanto aos critérios gerais de seleção de ferramentas, são apresentados na Tabela \ref{saiku}. 

\begin{table}[!ht]
\input{tabelas/saiku.ltx}
\caption{Características do Saiku Analytics e avaliação quanto aos critérios gerais de seleção de ferramentas}
\label{saiku}
\end{table}
\FloatBarrier

Na arquitetura do Saiku Analytics, está incorporado outro software livre chamado de Mondrian OLAP. Por meio dele, é possível realizar  consultas. Estas ocorrem por meio da escrita de \textit{queries} em linguagem MDX \textit{(MulitDimensional eXpressions)}que foi proposta por \citeonline{spofford2006mdx} como uma forma de escrever consultas mais otimizadas para bases seguem o modelo dimensional, tal como mostra o exemplo do trecho de Código-Fonte \ref{MDX}.


\begin{center}
\begin{minipage}{0.5\textwidth}

\begin{lstlisting}[caption=Exemplo de \textit{Query} em linguagem MDX, label=MDX]
 SELECT
   { [Measures].[Loja] } ON COLUMNS,
   { [Tempo].[2002], [Tempo].[2003] } ON ROWS
FROM Vendas
WHERE ( [Loja].[Loja Sul]) 

\end{lstlisting}
\end{minipage}
\end{center}
\FloatBarrier

\newpage
\section{Resumo Ferramental do Ambiente de \textit{Data Warehousing}}

Na Figura \ref{pentaho-tools}, é apresentado como cada uma das ferramentas apresentadas na seções anteriores está disposta na arquitetura do ambiente de \textit{Data Warehousing} para Métricas de Código-Fonte.

\begin{figure}[ht!]
\begin{center}
\includegraphics[keepaspectratio=true, scale=.20]{figuras/pentaho-tools.eps}
\caption{Arquitetura Ambiente de \textit{Data Warehousing} para Métricas de Código-Fonte}
\label{pentaho-tools}
\end{center}
\end{figure}
\FloatBarrier

A arquitetura descrita na Figura \ref{pentaho-tools} foi implementada em uma máquina virtual com as seguintes configurações

\begin{easylist}
& Processador: Intel(R) Xeon(R) CPU E5-2620 @ 2.00GHz
& RAM: 8GB
& Distribuição: Debian Whezzy
\end{easylist}